{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "import torch\n",
    "import time\n",
    "from load_dataset import load_dataset, add_label_id\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from models import T5Classifier, T5EncoderClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_id = {\"Web\": 0, \"International\": 1, \"Etat\": 2, \"Wirtschaft\": 3, \"Panorama\": 4,\n",
    "               \"Sport\": 5, \"Wissenschaft\": 6, \"Kultur\": 7, \"Inland\": 8}\n",
    "id_to_label = {0: \"Web\", 1:\"International\", 2: \"Etat\", 3: \"Wirtschaft\", 4: \"Panorama\",\n",
    "               5: \"Sport\", 6: \"Wissenschaft\", 7: \"Kultur\", 8: \"Inland\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "device = \"mps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5EncoderClassifier(loss_fn=loss_fn, lr=2e-6, use_gradient_clip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_model = \"./t5_results/encoder/model/model.pt\"\n",
    "model = torch.load(path_to_model, map_location=\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), model.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "simplified_labels = [\"Web\", \"International\", \"Etat\", \"Wirtschaft\", \"Panorama\", \"Sport\", \"Wissenschaft\", \n",
    "                     \"Kultur\", \"Heimat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_attentionmask = [1 for _ in range(len(label_to_id))]\n",
    "decoder_inputs = [model.tokenizer(simplified_label).input_ids[0] for simplified_label in simplified_labels]\n",
    "def tokenize_function(examples):\n",
    "    if model.is_transformer:\n",
    "        input_tokenized = model.tokenizer(examples[\"text\"], padding=\"max_length\", max_length=512, truncation=True)\n",
    "        return {\"input_ids\": input_tokenized.input_ids, \"input_attention_mask\": input_tokenized.attention_mask,\n",
    "                \"decoder_ids\": decoder_inputs, \"decoder_attention_mask\": decoder_attentionmask }\n",
    "    else:\n",
    "        return model.tokenizer(examples[\"text\"], padding=\"max_length\", max_length=512, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_label_id(example):\n",
    "    return {\"label_id\": label_to_id[example[\"label\"]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, test_ds = load_dataset(\"../German_newspaper_articles/10kGNAD/train.csv\", \n",
    "                                 \"../German_newspaper_articles/10kGNAD/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "717dd9c4e0654fc781ca7bc62959ee15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9245 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b262debc7bf94fa78dfc0ed767525063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1028 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ds = train_ds.map(tokenize_function)\n",
    "test_ds = test_ds.map(tokenize_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62afe20bf88047579fc45c804da5175a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9245 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a218456a9c5a4ef4884433ba87f83942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1028 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ds = train_ds.map(add_label_id)\n",
    "test_ds = test_ds.map(add_label_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5EncoderClassifier(\n",
       "  (loss_fn): CrossEntropyLoss()\n",
       "  (t5encoder_model): T5EncoderModel(\n",
       "    (shared): Embedding(32128, 1024)\n",
       "    (encoder): T5Stack(\n",
       "      (embed_tokens): Embedding(32128, 1024)\n",
       "      (block): ModuleList(\n",
       "        (0): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 16)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseActDense(\n",
       "                (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "                (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): ReLU()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1-23): 23 x T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseActDense(\n",
       "                (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "                (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): ReLU()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (linear1): Linear(in_features=524288, out_features=512, bias=True)\n",
       "  (linear2): Linear(in_features=512, out_features=9, bias=True)\n",
       "  (dropout1): Dropout(p=0.7, inplace=False)\n",
       "  (dropout2): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.set_format(\"torch\", device=\"mps\")\n",
    "model.to(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(val_data):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    all = 0\n",
    "    for data in val_data:\n",
    "        label_id = torch.unsqueeze(data['label_id'],0)\n",
    "        if model.is_transformer:\n",
    "            output = model(torch.unsqueeze(data['input_ids'], 0), torch.unsqueeze(data['input_attention_mask'], 0),\n",
    "                        torch.unsqueeze(data['decoder_ids'], 0), torch.unsqueeze(data['decoder_attention_mask'], 0))\n",
    "        else:\n",
    "            output = model(torch.unsqueeze(data['input_ids'], 0), torch.unsqueeze(data['attention_mask'], 0))\n",
    "                           \n",
    "        output = torch.argmax(output)\n",
    "        if label_id == output:\n",
    "            correct +=1\n",
    "        all += 1\n",
    "    print(f\"Eval accuracy: {(correct/all)*100:.2f}%\")\n",
    "    return (correct/all)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "batch_index = 0\n",
    "running_loss = 0\n",
    "epochs = 10\n",
    "train_eval = train_ds.train_test_split(test_size=0.2, shuffle=True)\n",
    "loss_ls = []\n",
    "accuracy_ls = []\n",
    "start_time = time.perf_counter()\n",
    "for i in range(epochs):\n",
    "    print(f\"Epoch: {i}\")\n",
    "    train_eval = train_eval.shuffle()\n",
    "    for j in range(int(len(train_eval[\"train\"])/batch_size)):\n",
    "        model.train()\n",
    "        batch = train_eval['train'][batch_index:batch_index+batch_size]\n",
    "        batch_index += batch_size\n",
    "        optimizer.zero_grad()\n",
    "        if model.is_transformer:\n",
    "            output = model(batch['input_ids'], batch['input_attention_mask'], batch['decoder_ids'], batch['decoder_attention_mask'])\n",
    "        else:\n",
    "            output = model(batch[\"input_ids\"], batch[\"attention_mask\"])\n",
    "\n",
    "        loss = model.loss_fn(output, batch[\"label_id\"])\n",
    "        loss.backward()\n",
    "        if model.use_gradient_clip:\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if j % 50 == 49:\n",
    "            print(f\"loss: {running_loss/50}\")\n",
    "            loss_ls.append(running_loss/50)\n",
    "            running_loss = 0\n",
    "        if j % 200 == 199:\n",
    "            accuracy_ls.append(eval(train_eval[\"test\"]))\n",
    "\n",
    "    batch_index = 0\n",
    "       \n",
    "end_time = time.perf_counter()\n",
    "duration = (end_time - start_time)/60\n",
    "print(f\"Training took {duration:0.4f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\"loss\": loss_ls,\n",
    "           \"accuracy\": accuracy_ls}\n",
    "path_to_save_metrics = \"./t5_results/transformer/metrics\"\n",
    "with open(path_to_save_metrics + f\"/metrics_{epochs}_epochs.csv\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file_writer = csv.DictWriter(file, fieldnames=metrics.keys())\n",
    "    file_writer.writeheader()\n",
    "    file_writer.writerow(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_steps = [(i+1)*50 for i in range(len(loss_ls))]\n",
    "accuracy_steps = [(i+1)*200 for i in range(len(accuracy_ls))]\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "plt.gca().ticklabel_format(axis='both', style='plain', useOffset=False)\n",
    "ax1.plot(loss_steps, loss_ls, 'r-')\n",
    "ax2.plot(accuracy_steps, accuracy_ls, 'g-')\n",
    "ax1.set_xlabel('Steps')\n",
    "ax1.set_ylabel('Loss', color='r')\n",
    "ax2.set_ylabel('Accuracy', color='g')\n",
    "\n",
    "plt.title('T5 base')\n",
    "txt = f\"lr={model.lr}, batch_size={batch_size}, epochs={epochs}, gradient_clip=1.0 \\n Training duration: {duration:0.2f} minutes\"\n",
    "plt.figtext(0.5, -0.05, txt, wrap=True, horizontalalignment='center', fontsize=12)\n",
    "\n",
    "plt.savefig(path_to_save_metrics + f\"/graph_{epochs}_epochs.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "correct_dict = {\"Web\": 0, \"International\": 0, \"Etat\": 0, \"Wirtschaft\": 0, \"Panorama\": 0, \"Sport\": 0, \"Wissenschaft\": 0, \"Kultur\": 0,\n",
    "                \"Inland\": 0}\n",
    "wrong = []\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_ds.set_format(\"torch\", device=device)\n",
    "    start_time = time.perf_counter()\n",
    "    for data in test_ds:\n",
    "        label_id = torch.unsqueeze(data['label_id'], 0)\n",
    "        if model.is_transformer:\n",
    "            output = model(torch.unsqueeze(data['input_ids'], 0), torch.unsqueeze(data['input_attention_mask'], 0),\n",
    "                        torch.unsqueeze(data['decoder_ids'], 0), torch.unsqueeze(data['decoder_attention_mask'], 0))\n",
    "        else:\n",
    "            output = model(torch.unsqueeze(data['input_ids'], 0), torch.unsqueeze(data['attention_mask'], 0))\n",
    "\n",
    "        output = torch.argmax(output)\n",
    "        if label_id == output:\n",
    "            global correct_dict\n",
    "            correct_dict[id_to_label[output.item()]] += 1\n",
    "            global correct\n",
    "            correct +=1\n",
    "        else:\n",
    "            pred = {\"sample\": data[\"text\"], \"prediction\": id_to_label[output.item()], \"label\": data[\"label\"]}\n",
    "            wrong.append(pred)\n",
    "    end_time = time.perf_counter()\n",
    "    print(f\"Test took {(end_time - start_time)/60:0.4f} minutes\")\n",
    "    return (correct/len(test_ds))*100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test took 2.7429 minutes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "90.27237354085604"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_test = test()\n",
    "accuracy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sample': '\"Ich will etwas Festes, Greifbares in meiner Hand\", sagt der Regisseur. Hollywood – Inmitten steigender Beliebtheit von Online-Videodiensten wie Netflix, Hulu oder Amazon hält einer weiter an VHS-Kassetten und DVDs fest: Quentin Tarantino. Ich kann mit Streaming nichts anfangen, schreibt der US-Kultregisseur (Inglourious Basterds) in Tom Rostons Buch I Lost It At The Video Store. Ich will etwas Festes, Greifbares in meiner Hand. Ich schaue auch keine Filme auf dem Laptop. Der 52-Jährige habe sogar erst kürzlich seine haptische Filmbibliothek ausgebaut, indem er das Inventar der kalifornischen Videothek Video Archives aufgekauft hat. Sie sind in Konkurs gegangen, also habe ich ihr gesamtes Inventar gekauft, vermutlich so um die 8.000 Kassetten und DVDs, wird Tarantino, der vor seinem Durchbruch mit Pulp Fiction 1994 in der Videothek arbeitete, vom Filmportal Indiewire aus dem Buch zitiert. Ich nehme auch noch Filme, die im Fernsehen laufen, auf Kassette auf, damit die Sammlung wächst. Tarantino besitzt in Los Angeles zudem das New Beverly Cinema, das ausschließlich analoge Filme vorführt. Tarantino drehte zuletzt The Hateful Eight, der rund um Weihnachten in den US-Kinos starten soll. Der Western dreht sich um acht Charaktere, darunter ein Kopfgeldjäger und ein General, die in einem Wintersturm an einer Postkutschenstation in den Bergen festsitzen. Samuel L. Jackson, Kurt Russell, Bruce Dern, Jennifer Jason Leigh und Demian Bichir gehören zur Besetzung.',\n",
       " 'prediction': 'Kultur',\n",
       " 'label': '\"Ich will etwas Festes, Greifbares in meiner Hand\", sagt der Regisseur. Hollywood – Inmitten steigender Beliebtheit von Online-Videodiensten wie Netflix, Hulu oder Amazon hält einer weiter an VHS-Kassetten und DVDs fest: Quentin Tarantino. Ich kann mit Streaming nichts anfangen, schreibt der US-Kultregisseur (Inglourious Basterds) in Tom Rostons Buch I Lost It At The Video Store. Ich will etwas Festes, Greifbares in meiner Hand. Ich schaue auch keine Filme auf dem Laptop. Der 52-Jährige habe sogar erst kürzlich seine haptische Filmbibliothek ausgebaut, indem er das Inventar der kalifornischen Videothek Video Archives aufgekauft hat. Sie sind in Konkurs gegangen, also habe ich ihr gesamtes Inventar gekauft, vermutlich so um die 8.000 Kassetten und DVDs, wird Tarantino, der vor seinem Durchbruch mit Pulp Fiction 1994 in der Videothek arbeitete, vom Filmportal Indiewire aus dem Buch zitiert. Ich nehme auch noch Filme, die im Fernsehen laufen, auf Kassette auf, damit die Sammlung wächst. Tarantino besitzt in Los Angeles zudem das New Beverly Cinema, das ausschließlich analoge Filme vorführt. Tarantino drehte zuletzt The Hateful Eight, der rund um Weihnachten in den US-Kinos starten soll. Der Western dreht sich um acht Charaktere, darunter ein Kopfgeldjäger und ein General, die in einem Wintersturm an einer Postkutschenstation in den Bergen festsitzen. Samuel L. Jackson, Kurt Russell, Bruce Dern, Jennifer Jason Leigh und Demian Bichir gehören zur Besetzung.'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(wrong))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_to_save_metrics + \"/test_evaluation.csv\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file_writer = csv.DictWriter(file, fieldnames=correct_dict.keys())\n",
    "    file_writer.writeheader()\n",
    "    file_writer.writerow(correct_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = Counter(test_ds[\"label\"])\n",
    "label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(label_counts.keys())\n",
    "differences = dict()\n",
    "for label in labels:\n",
    "    differences[label] = correct_dict[label]/label_counts[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_values = [value*100 for value in differences.values()]\n",
    "difference_labels = [value for value in differences.keys()]\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "xs = range(len(difference_labels))\n",
    "ys = [difference_values[x] for x in xs]\n",
    "\n",
    "ax.bar(difference_labels, ys, 0.6)\n",
    "plt.title(\"correct per category\")\n",
    "plt.xlabel(\"category\")\n",
    "plt.ylabel(\"accuracy in %\")\n",
    "plt.setp(ax.get_xticklabels(), rotation=30, horizontalalignment='right')\n",
    "plt.savefig(path_to_save_metrics + \"/test_evaluation.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_model = \"./t5_results/model/model.pt\"\n",
    "torch.save(model, path_to_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv.nosync",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
